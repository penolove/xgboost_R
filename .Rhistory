return_string=""
for (i in 1:nrow(x)){
return_string=paste(return_string,paste(x[i,],collapse=","),sep="\n")
}
return_string
x=bs_power_lever
return_string=""
for (i in 1:nrow(x)){
if(i==1){
return_string=paste(x[i,],collapse=",")
}else{
return_string=paste(return_string,paste(x[i,],collapse=","),sep="\n")
}
}
return_string
install.packages('hexbin')
install.packages('RColorBrewer')
library(hexbin)
library(RColorBrewer)
library(MASS)
w=read.csv('whoutput.csv', header=FALSE)
df <- data.frame(w)
h <- hexbin(df)
rf <- colorRampPalette(rev(brewer.pal(11,'Spectral')))
plot(h, colramp=rf)
h1 <- hist(df$V1, breaks=25, plot=F)
h2 <- hist(df$V2, breaks=25, plot=F)
top <- max(h1$counts, h2$counts)
k <- kde2d(df$V1, df$V2, n=25)
r <- rf(32)
# margins
oldpar <- par()
par(mar=c(3,3,1,1))
layout(matrix(c(2,0,1,3),2,2,byrow=T),c(3,1), c(1,3))
image(k, col=r) #plot the image
par(mar=c(0,2,1,0))
barplot(h1$counts, axes=F, ylim=c(0, top), space=0, col='red')
par(mar=c(2,0,0.5,1))
barplot(h2$counts, axes=F, xlim=c(0, top), space=0, col='red', horiz=T)
mean(df$V1)
mean(df$V2)
h1 <- hist(df$V1, breaks=50, plot=F)
h2 <- hist(df$V2, breaks=50, plot=F)
top <- max(h1$counts, h2$counts)
k <- kde2d(df$V1, df$V2, n=50)
r <- rf(32)
# margins
oldpar <- par()
par(mar=c(3,3,1,1))
layout(matrix(c(2,0,1,3),2,2,byrow=T),c(3,1), c(1,3))
image(k, col=r) #plot the image
par(mar=c(0,2,1,0))
barplot(h1$counts, axes=F, ylim=c(0, top), space=0, col='red')
par(mar=c(2,0,0.5,1))
barplot(h2$counts, axes=F, xlim=c(0, top), space=0, col='red', horiz=T)
mean(df$V1)
mean(df$V2)
plot(h, colramp=rf)
mean(df$V1)
mean(df$V2)
oldpar <- par()
par(mar=c(3,3,1,1))
layout(matrix(c(2,0,1,3),2,2,byrow=T),c(3,1), c(1,3))
image(k, col=r) #plot the image
par(mar=c(0,2,1,0))
barplot(h1$counts, axes=F, ylim=c(0, top), space=0, col='red')
par(mar=c(2,0,0.5,1))
barplot(h2$counts, axes=F, xlim=c(0, top), space=0, col='red', horiz=T)
mean(df$V1)
mean(df$V2)
plot(h, colramp=rf)
library(hexbin)
library(RColorBrewer)
library(MASS)
#w=read.csv('whoutput.csv', header=FALSE)
w=read.csv('output.csv', header=FALSE)
df <- data.frame(w)
h <- hexbin(df)
rf <- colorRampPalette(rev(brewer.pal(11,'Spectral')))
plot(h, colramp=rf)
h1 <- hist(df$V1, breaks=50, plot=F)
h2 <- hist(df$V2, breaks=50, plot=F)
top <- max(h1$counts, h2$counts)
k <- kde2d(df$V1, df$V2, n=50)
r <- rf(32)
# margins
oldpar <- par()
par(mar=c(3,3,1,1))
layout(matrix(c(2,0,1,3),2,2,byrow=T),c(3,1), c(1,3))
image(k, col=r) #plot the image
par(mar=c(0,2,1,0))
barplot(h1$counts, axes=F, ylim=c(0, top), space=0, col='red')
par(mar=c(2,0,0.5,1))
barplot(h2$counts, axes=F, xlim=c(0, top), space=0, col='red', horiz=T)
mean(df$V1)
mean(df$V2)
rf <- colorRampPalette(rev(brewer.pal(11,'Spectral')))
plot(h, colramp=rf)
w=read.csv('whoutput.csv', header=FALSE)
library(cluster)
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
library(cluster)
k.max=15
wss <- sapply(1:k.max,
function(k){kmeans(w, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
op=kmeans(w, 4, nstart=10 )
op$centers
w=read.csv('output.csv', header=FALSE)
library(cluster)
k.max=15
wss <- sapply(1:k.max,
function(k){kmeans(w, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
library(cluster)
k.max=15
wss <- sapply(1:k.max,
function(k){kmeans(w, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
op=kmeans(w, 4, nstart=10 )
op$centers
w=read.csv('whoutput.csv', header=FALSE)
library(cluster)
k.max=15
wss <- sapply(1:k.max,
function(k){kmeans(w, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
op=kmeans(w, 4, nstart=10 )
op$centers
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
op=kmeans(w, 4, nstart=10 )
op$centers
w=read.csv('output.csv', header=FALSE)
library(cluster)
k.max=15
wss <- sapply(1:k.max,
function(k){kmeans(w, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
54/37
120/80
189/127
296/198
144/97
39/28
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
data(agaricus.train, package='xgboost')
x=agaricus.train$data
load("C:/Users/User/Desktop/project/4GLTE/source code/LTEextreaction.rdata.RData")
View(x)
x[,2:14]
type(x[,2:14])
class(x[,2:14])
class(x[1,14])
type(x[1,14])
trian=x[1,14]
trian=x[,2:14]
View(x)
y=x[,15]
y=as.numeric(x[,15])
y=as.numeric(x[,15])-1
nrow(x)
sample(nrow(x)*0.8, 3)
sample(nrow(x)*0.8, 3)
sample(nrow(x), nrow(x)*0.2)
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 20, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
library(xgboost)
vali_idx=sample(nrow(x), nrow(x)*0.2)
train_x=x[-vali_idx,2:14]
train_y=as.numeric(x[-vali_idx,15])-1
vali_x=x[vali_idx,2:14]
vali_y=as.numeric(x[vali_idx,15])-1
dtrain<- xgb.DMatrix(data.matrix(train_x), label=(train_y))
dtrain<- xgb.DMatrix(data.matrix(vali_x), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 20, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
library(xgboost)
vali_idx=sample(nrow(x), nrow(x)*0.2)
train_x=as.numeric((x[-vali_idx,2:14])
train_y=as.numeric(x[-vali_idx,15])-1
vali_x=as.numeric(x[vali_idx,2:14])
vali_y=as.numeric(x[vali_idx,15])-1
dtrain<- xgb.DMatrix(data.matrix(train_x), label=(train_y))
dtrain<- xgb.DMatrix(data.matrix(vali_x), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 20, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
train_x=as.numeric((x[-vali_idx,2:14])
train_y=as.numeric(x[-vali_idx,15]-1)
vali_x=as.numeric(x[vali_idx,2:14])
vali_y=as.numeric(x[vali_idx,15]-1)
dtrain<- xgb.DMatrix(data.matrix(train_x), label=(train_y))
dtrain<- xgb.DMatrix(data.matrix(vali_x), label=(vali_y))
dtrain<- xgb.DMatrix(as.matrix(train_x), label=(train_y))
dtrain<- xgb.DMatrix(as.matrix(train_x))
train_x=as.numeric((x[-vali_idx,2:14])
train_x=as.numeric((x[-vali_idx,2:14]))
dtrain<- xgb.DMatrix(as.matrix(train_x))
train_x
train_x[1,1]
class(train_x[1,1])
dtrain<- xgb.DMatrix(as.matrix(train_x))
dtrain<- xgb.DMatrix(as.matrix(sapply(trainG1, as.numeric)))
dtrain<- xgb.DMatrix(as.matrix(sapply(train_x, as.numeric)))
dtrain<- xgb.DMatrix(as.matrix(sapply(train_x, as.numeric)),label=(train_y))
dtrain<- xgb.DMatrix(train_x,label=(train_y))
class(train_x)
dtrain<- xgb.DMatrix(train_x,label=(train_y))
class(train_x[,1])
class(train_x[,2])
class(train_x[,3])
train_x=x[-vali_idx,2:14]
dtrain<- xgb.DMatrix(train_x,label=(train_y))
train_x=as.numeric(x[-vali_idx,2:14])
dtrain<- xgb.DMatrix(train_x,label=(train_y))
dtrain<- xgb.DMatrix(as.dataframe(train_x),label=(train_y))
dtrain<- xgb.DMatrix(as.data.frame(train_x),label=(train_y))
View(train_x)
dtrain<- xgb.DMatrix(as.matrix(train_x),label=(train_y))
dtrain<- xgb.DMatrix(as.matrix(sapply(train_x, as.numeric)),label=(train_y))
dtrain<- xgb.DMatrix(as.matrix(sapply(vali_x, as.numeric)), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
dval<- xgb.DMatrix(as.matrix(sapply(vali_x, as.numeric)), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
dval<- xgb.DMatrix(as.matrix(sapply(vali_x, as.numeric)), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 20, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
vali_y
train_x=as.numeric(x[-vali_idx,2:14])
train_y=as.numeric(x[-vali_idx,15])-1
vali_x=as.numeric(x[vali_idx,2:14])
vali_y=as.numeric(x[vali_idx,15])-1
dtrain<- xgb.DMatrix(as.matrix(sapply(train_x, as.numeric)),label=(train_y))
dval<- xgb.DMatrix(as.matrix(sapply(vali_x, as.numeric)), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 20, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
vali_y
x[vali_idx,15]
x[vali_idx,15]$Levels
level(x[vali_idx,15])
levels(x[vali_idx,15])
load("LTEextreaction.rdata.RData")
setwd("C:/Users/User/Desktop/project/4GLTE/source code/")
load("LTEextreaction.rdata.RData")
remains<-names(which(table(x$label)>=50))
h1<-x$label %in% remains
x<-x[h1,]
level(x[,15])
levels(x[,15])
x[,15]=factor(x[,15])
vali_idx=sample(nrow(x), nrow(x)*0.2)
train_x=as.numeric(x[-vali_idx,2:14])
train_y=as.interger(x[-vali_idx,15])-1
x[,15]=factor(x[,15])
vali_idx=sample(nrow(x), nrow(x)*0.2)
train_x=as.numeric(x[-vali_idx,2:14])
train_y=as.integer(x[-vali_idx,15])-1
library(xgboost)
setwd("C:/Users/User/Desktop/project/4GLTE/source code/")
load("LTEextreaction.rdata.RData")
remains<-names(which(table(x$label)>=50))
h1<-x$label %in% remains
x<-x[h1,]
x[,15]=factor(x[,15])
vali_idx=sample(nrow(x), nrow(x)*0.2)
train_x=as.numeric(x[-vali_idx,2:14])
x[-vali_idx,2:14]
train_x=as.matrix(sapply(x[-vali_idx,2:14], as.numeric))
for (i in 2:14){
print(class(x[,i]))
}
print(class(x))
for (i in 2:14){
print(class(x[,i]))
}
train_x=as.matrix(sapply(x[-vali_idx,2:14], as.numeric))
train_y=as.integer(x[-vali_idx,15])-1
vali_x=as.matrix(sapply(x[vali_idx,2:14], as.numeric))
vali_y=as.integer(x[vali_idx,15])-1
dtrain<- xgb.DMatrix(as.matrix(sapply(train_x, as.numeric)),label=(train_y))
dval<- xgb.DMatrix(as.matrix(sapply(vali_x, as.numeric)), label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
library(xgboost)
setwd("C:/Users/User/Desktop/project/4GLTE/source code/")
load("LTEextreaction.rdata.RData")
remains<-names(which(table(x$label)>=50))
h1<-x$label %in% remains
x<-x[h1,]
x[,15]=factor(x[,15])
vali_idx=sample(nrow(x), nrow(x)*0.2)
print(class(x))
for (i in 2:14){
print(class(x[,i]))
}
train_x=as.matrix(sapply(x[-vali_idx,2:14], as.numeric))
train_y=as.integer(x[-vali_idx,15])-1
nrow(train_x)
length(train_y)
dtrain<- xgb.DMatrix(as.matrix(sapply(train_x, as.numeric)),label=(train_y))
dtrain<- xgb.DMatrix(train_x,label=(train_y))
train_x=as.matrix(sapply(x[-vali_idx,2:14], as.numeric))
train_y=as.integer(x[-vali_idx,15])-1
vali_x=as.matrix(sapply(x[vali_idx,2:14], as.numeric))
vali_y=as.integer(x[vali_idx,15])-1
dtrain<- xgb.DMatrix(train_x,label=(train_y))
dval<- xgb.DMatrix(vali_x, label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = 20
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 20, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
length(levels(x[,15]))
n_class=length(levels(x[,15]))
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 300, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 3000, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
xgb.DMatrix.save(dtrain, 'xgb.DMatrix.data')
xgb.save(bst, 'xgb.model')
View(train_x)
ncol(train_x\)
ncol(train_x)
mat=c(1,2,3,4,5,6,1,2,3,4,5,6,1)
dtest <-xgb.DMatrix(as.matrix(mat))
pred0 = predict(bst,dtest)
pred0
dtest
dtest$as.matrix(mat)
as.matrix(mat)
mat=c(1,2,3,4,5,6,1,2,3,4,5,6,1)
dtest <-xgb.DMatrix(matrix(mat,nrow=1))
matrix(mat,nrow=1)
pred0 = predict(bst,dtest)
pred0
library(xgboost)
setwd("C:/Users/User/Desktop/Andy20170107/")
load("LTEextreaction.rdata.RData")
remains<-names(which(table(x$label)>=50))
h1<-x$label %in% remains
library(xgboost)
setwd("C:/Users/User/Desktop/Andy/20170107")
load("LTEextreaction.rdata.RData")
remains<-names(which(table(x$label)>=50))
h1<-x$label %in% remains
x<-x[h1,]
x[,15]=factor(x[,15])
n_class=length(levels(x[,15]))
vali_idx=sample(nrow(x), nrow(x)*0.2)
print(class(x))
for (i in 2:14){
print(class(x[,i]))
}
train_x=as.matrix(sapply(x[-vali_idx,2:14], as.numeric))
train_y=as.integer(x[-vali_idx,15])-1
vali_x=as.matrix(sapply(x[vali_idx,2:14], as.numeric))
vali_y=as.integer(x[vali_idx,15])-1
dtrain<- xgb.DMatrix(train_x,label=(train_y))
dval<- xgb.DMatrix(vali_x, label=(vali_y))
param <- list(  objective           = "multi:softprob",
eta                 = 0.05 , # 0.06, #0.01,
eval_metric         = "merror",
max_depth           = 3, #changed from default of 15
subsample           = 0.3, # 0.9
num_class           = n_class
)
watchlist <- list(eval = dval,train=dtrain)
bst <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 3000, #300, #280, #125, #250, # changed from 300
verbose             = 1,
early.stop.round    = 250,
watchlist           = watchlist
)
xgb.DMatrix.save(dtrain, 'xgb.DMatrix.data')
mat=c(1,2,3,4,5,6,1,2,3,4,5,6,1)
xgb.save(bst, 'xgb.model')
dtest <-xgb.DMatrix(matrix(mat,nrow=1))
pred0 = predict(bst,dtest)
